{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65944684-c8b6-4acd-af61-5a20567827f1",
   "metadata": {},
   "source": [
    "### 1. Reading the OpenAI API Key\n",
    "\n",
    "This cell imports the `os` module and reads the `OPENAI_API_KEY` from the environment variables.  \n",
    "The key is stored in `openai_api_key` so that later cells can use OpenAI models securely without hard-coding the key in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f930139-fc19-4a51-b5b1-69bce0981852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a2cd52-4d09-4260-a10a-444df4ec1a9c",
   "metadata": {},
   "source": [
    "### 2. Verifying API Key Availability\n",
    "\n",
    "Here we check for the presence of the environment variable `OPENAI_API_KEY`.\n",
    "If the key is missing, the assertion will fail with a clear error message, preventing the rest of the notebook from running without proper configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4305f664-cafd-40a4-b8fa-457791b014d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"OPENAI_API_KEY\" in os.environ, \"Set OPENAI_API_KEY env variable.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea253233-84cb-4d4c-a850-f75ee088b875",
   "metadata": {},
   "source": [
    "### 3. Installing Required Packages\n",
    "\n",
    "This cell installs all external Python packages used in the notebook, including:\n",
    "\n",
    "- `langchain-core`, `langchain-community`, `langchain-openai`, `langchain-text-splitters`\n",
    "- `langgraph`, `langsmith`\n",
    "- `faiss-cpu` (for vector search)\n",
    "- `pypdf` (for PDF handling)\n",
    "\n",
    "These dependencies provide the building blocks for the RAG (Retrieval-Augmented Generation) pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d484b77-26fe-4c1f-b356-e48ec352c9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-core in ./.local/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in ./.local/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai in ./.local/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters in ./.local/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: langgraph in ./.local/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: langsmith in ./.local/lib/python3.10/site-packages (0.4.46)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/site-packages (1.7.4)\n",
      "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/site-packages (3.17.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.10/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.10/site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.local/lib/python3.10/site-packages (from langchain-core) (2.12.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.10/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/site-packages (from langchain-core) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.local/lib/python3.10/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in ./.local/lib/python3.10/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.10/site-packages (from langchain-community) (1.4.20)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in ./.local/lib/python3.10/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/site-packages (from langchain-community) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./.local/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./.local/lib/python3.10/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.local/lib/python3.10/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.10/site-packages (from langchain-community) (1.26.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in ./.local/lib/python3.10/site-packages (from langchain-openai) (1.109.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in ./.local/lib/python3.10/site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in ./.local/lib/python3.10/site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.local/lib/python3.10/site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.local/lib/python3.10/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from langsmith) (0.25.2)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.local/lib/python3.10/site-packages (from langsmith) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.local/lib/python3.10/site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.local/lib/python3.10/site-packages (from langsmith) (0.25.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.2)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (2.3)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./.local/lib/python3.10/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.local/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  langchain-core langchain-community langchain-openai langchain-text-splitters langgraph langsmith faiss-cpu pypdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf0a8f-e951-4c49-b140-61a03e6c9c90",
   "metadata": {},
   "source": [
    "### 4. Core Python Imports\n",
    "\n",
    "This cell imports core Python utilities:\n",
    "\n",
    "- `os` – operating system and environment variables\n",
    "- `textwrap` – for building readable prompt templates\n",
    "- `typing` – type hints such as `List`, `Dict`, `Any`, `TypedDict`, and `Annotated`\n",
    "\n",
    "These are used throughout the notebook for cleaner code and better structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cadf519-32ec-461d-936b-688b79cf01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from typing import List, Dict, Any, TypedDict, Annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd57a8-f3f2-4d8d-b8ca-c2d0f15cef02",
   "metadata": {},
   "source": [
    "### 5. LangChain and OpenAI Imports\n",
    "\n",
    "This cell imports all the main components from LangChain and related libraries:\n",
    "\n",
    "- `ChatOpenAI`, `OpenAIEmbeddings` for calling OpenAI chat models and generating vector embeddings.\n",
    "- `PyPDFLoader` for loading and parsing PDF documents.\n",
    "- `FAISS` for building a vector store used in semantic search.\n",
    "- `RecursiveCharacterTextSplitter` for splitting long documents into chunks.\n",
    "- `ChatPromptTemplate`, `RunnablePassthrough`, `RunnableLambda`, `RunnableWithMessageHistory` for building composable RAG chains.\n",
    "\n",
    "These imports are the foundation of the RAG pipeline built in the rest of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ddb7bc-2574-4cc7-b717-acc2a553f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"OPENAI_API_KEY\" in os.environ, \"Please set OPENAI_API_KEY environment variable.\"\n",
    "\n",
    "# LangChain / OpenAI (modern modular imports)\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import (\n",
    "    RunnablePassthrough,\n",
    "    RunnableLambda,\n",
    "    RunnableWithMessageHistory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda285e5-7d5b-41ed-a904-057170ea182e",
   "metadata": {},
   "source": [
    "### 6. Conversation History and LangGraph Imports\n",
    "\n",
    "This cell imports:\n",
    "\n",
    "- Message history abstractions (`BaseChatMessageHistory`, `ChatMessageHistory`) to store past chat turns.\n",
    "- Message types (`HumanMessage`, `AIMessage`, `AnyMessage`) to represent interactions.\n",
    "- LangGraph tools (`StateGraph`, `END`, `add_messages`, `MemorySaver`) to construct a simple agent with memory.\n",
    "\n",
    "These are later used to build a stateful conversational agent on top of the RAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a85ada-9cd4-4e5e-a077-e238fc59e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage, AnyMessage\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dadf767-76da-4583-aa0d-bea2d5bd5bb8",
   "metadata": {},
   "source": [
    "### 7. Utilities, Tracing, and Directory Setup\n",
    "\n",
    "This cell:\n",
    "\n",
    "- Imports `requests`, `pathlib`, `json`, and `re` for HTTP requests, filesystem paths, JSON handling, and regular expressions.\n",
    "- Optionally configures LangChain/LangSmith tracing (disabled by default).\n",
    "- Defines base directories (`data`, `processed`, `faiss_index`) and ensures they exist.\n",
    "\n",
    "These paths are used to store the GDPR PDF, processed chunks, and the FAISS index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "809f1e6b-d270-4710-99f5-84cda1ffc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pathlib\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Enable LangSmith tracing (optional, will be no-op if you have no LangSmith setup)\n",
    "os.environ.setdefault(\"LANGCHAIN_TRACING_V2\", \"false\")\n",
    "#os.environ.setdefault(\"LANGCHAIN_PROJECT\", \"gdpr-rag-project\")\n",
    "\n",
    "# Global paths\n",
    "BASE_DIR = pathlib.Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "FAISS_DIR = PROCESSED_DIR / \"faiss_index\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1ca50-a74d-44e9-a68c-919cb912e069",
   "metadata": {},
   "source": [
    "### 8. GDPR PDF Location and Source URL\n",
    "\n",
    "Here we define:\n",
    "\n",
    "- The local file path where the GDPR PDF will be stored.\n",
    "- The official URL from which the GDPR PDF is downloaded.\n",
    "\n",
    "This setup is used in the next cell to ensure the document is available locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19542f55-4298-45f9-8e5e-cfff3fe3218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpr_pdf_path = DATA_DIR / \"GDPR.pdf\"\n",
    "gdpr_url = \"https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2288f341-83c9-448a-bfe2-ed1e654de3a0",
   "metadata": {},
   "source": [
    "### 9. Downloading the GDPR PDF (If Needed)\n",
    "\n",
    "This cell checks whether the GDPR PDF already exists locally.  \n",
    "If it does not:\n",
    "\n",
    "1. It downloads the PDF from the official URL using `requests`.\n",
    "2. Saves the content to `gdpr_pdf_path`.\n",
    "\n",
    "If it already exists, it simply prints a confirmation message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00fde338-713b-4713-a3eb-d847a67e7232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDPR PDF already exists at: data/GDPR.pdf\n"
     ]
    }
   ],
   "source": [
    "if not gdpr_pdf_path.exists():\n",
    "    print(\"Downloading GDPR PDF...\")\n",
    "    resp = requests.get(gdpr_url)\n",
    "    resp.raise_for_status()\n",
    "    with open(gdpr_pdf_path, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "    print(\"Downloaded GDPR to:\", gdpr_pdf_path)\n",
    "else:\n",
    "    print(\"GDPR PDF already exists at:\", gdpr_pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0383ef-b5d8-4de1-b93b-335500b71459",
   "metadata": {},
   "source": [
    "### 10. Loading the GDPR PDF into Documents\n",
    "\n",
    "Here we:\n",
    "\n",
    "- Create a `PyPDFLoader` using the local GDPR PDF path.\n",
    "- Load the document into `docs`, which is a list of page-level documents.\n",
    "- Print how many pages were successfully loaded.\n",
    "\n",
    "These `docs` form the raw text data that will later be chunked and indexed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f3a319b-e6d8-40dc-a2f4-3fadb468f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GDPR PDF...\n",
      "Loaded 88 pages.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading GDPR PDF...\")\n",
    "loader = PyPDFLoader(str(gdpr_pdf_path))\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} pages.\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c65ef-b320-4ff9-b5e8-19f566e6b996",
   "metadata": {},
   "source": [
    "### 11. Configuring the Text Splitter\n",
    "\n",
    "This cell defines a `RecursiveCharacterTextSplitter`:\n",
    "\n",
    "- `chunk_size=1000` characters\n",
    "- `chunk_overlap=150` characters\n",
    "- Custom separators based on newlines and punctuation\n",
    "\n",
    "The splitter will break each page into overlapping chunks suitable for embedding and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55dbd4cb-07ec-4ea0-b13f-e69c2a249ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f5629e-509f-4d96-b2c2-5917696419cb",
   "metadata": {},
   "source": [
    "### 12. Splitting the Document into Chunks\n",
    "\n",
    "We now apply the configured splitter to `docs`:\n",
    "\n",
    "- The GDPR text is divided into overlapping chunks.\n",
    "- The total number of resulting chunks is printed.\n",
    "\n",
    "These chunks will be embedded and stored in a vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f2f90b5-ce40-41d3-80b5-2413d73cb31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into chunks...\n",
      "Created 461 chunks.\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting into chunks...\")\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"Created {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93448377-056e-40a1-9c21-287eb0527bcd",
   "metadata": {},
   "source": [
    "### 13. Tagging Chunks with Article Metadata\n",
    "\n",
    "This cell inspects each chunk and tries to extract an `Article <number>` pattern using a regular expression.  \n",
    "\n",
    "- If an article number is found, it is stored in the chunk’s metadata.\n",
    "- Otherwise, the article is marked as `\"unknown\"`.\n",
    "\n",
    "These metadata tags are later used in formatting and citing GDPR sections in answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09cb4401-7e2b-49f8-a940-254227f319cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in chunks:\n",
    "    text = d.page_content\n",
    "    match = re.search(r\"Article\\s+(\\d+)\", text)\n",
    "    if match:\n",
    "        d.metadata[\"article\"] = match.group(1)\n",
    "    else:\n",
    "        d.metadata.setdefault(\"article\", \"unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba421e-f908-4e23-b649-68060f912427",
   "metadata": {},
   "source": [
    "### 14. Saving a Preview of Chunks\n",
    "\n",
    "This cell writes a JSON preview of the first 50 chunks into `chunks_preview.json`.  \n",
    "For each chunk it stores:\n",
    "\n",
    "- Page number\n",
    "- Article number\n",
    "- A short content preview\n",
    "\n",
    "This makes it easy to inspect how the GDPR text was split and tagged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43e8cbcb-e05e-4944-896f-e8b7e82bafc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks prepared and preview saved.\n"
     ]
    }
   ],
   "source": [
    "with open(PROCESSED_DIR / \"chunks_preview.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        [\n",
    "            {\n",
    "                \"page\": c.metadata.get(\"page\"),\n",
    "                \"article\": c.metadata.get(\"article\"),\n",
    "                \"content_preview\": c.page_content[:300],\n",
    "            }\n",
    "            for c in chunks[:50]\n",
    "        ],\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "print(\"Chunks prepared and preview saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74bab32-bbac-4bc8-835d-7b84114409ac",
   "metadata": {},
   "source": [
    "### 15. Building and Saving the FAISS Vector Index\n",
    "\n",
    "In this step we:\n",
    "\n",
    "1. Create an `OpenAIEmbeddings` object using the `text-embedding-3-small` model.\n",
    "2. Convert all chunks into embeddings and store them in a FAISS vector index.\n",
    "3. Persist the FAISS index to disk under `FAISS_DIR`.\n",
    "\n",
    "This index enables efficient semantic search over GDPR text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34783d10-5417-42b9-9621-9f717c05e739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings and FAISS index...\n",
      "FAISS index saved to: data/processed/faiss_index\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating embeddings and FAISS index...\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectordb = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "FAISS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "vectordb.save_local(str(FAISS_DIR))\n",
    "\n",
    "print(\"FAISS index saved to:\", FAISS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beac344-d062-4dcc-b556-50a59f17b218",
   "metadata": {},
   "source": [
    "### 16. Reloading the FAISS Index\n",
    "\n",
    "This cell simulates a fresh start:\n",
    "\n",
    "- It reloads the FAISS index from disk using the same embedding model.\n",
    "- Prints a confirmation once the index is successfully loaded.\n",
    "\n",
    "This demonstrates how the vector database can be reused across sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0d3a7a7-6155-48b6-8ba9-6bf5ea733d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading FAISS index from disk...\n",
      "FAISS index loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"Reloading FAISS index from disk...\")\n",
    "vectordb = FAISS.load_local(\n",
    "    str(FAISS_DIR),\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "print(\"FAISS index loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac8f67-41c2-4a90-9668-1b9cb3a9b587",
   "metadata": {},
   "source": [
    "### 17. Creating the Retriever and LLM\n",
    "\n",
    "Here we:\n",
    "\n",
    "- Wrap the FAISS vector store as a `retriever` that returns the top 4 similar chunks.\n",
    "- Instantiate a deterministic chat model (`gpt-4o-mini` with `temperature=0`) to generate grounded answers.\n",
    "\n",
    "The retriever + LLM combination forms the core of the RAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b53d0a4-08d5-4d4e-a0e2-1e7747d6f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c250656-05b0-4b07-8147-3078795ed219",
   "metadata": {},
   "source": [
    "### 18. Formatting Retrieved Chunks\n",
    "\n",
    "This helper function takes a list of retrieved documents and formats them as:\n",
    "\n",
    "`[page X, article Y]`  \n",
    "followed by the text content.\n",
    "\n",
    "The formatted string is used as context in the prompt so the model can both answer and cite relevant GDPR sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e909d435-c1fe-401d-8a87-06477737a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    out = []\n",
    "    for d in docs:\n",
    "        page = d.metadata.get(\"page\", \"?\")\n",
    "        article = d.metadata.get(\"article\", \"unknown\")\n",
    "        header = f\"[page {page}, article {article}]\"\n",
    "        out.append(header + \"\\n\" + d.page_content)\n",
    "    return \"\\n\\n\".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1eddc-c9cc-4a57-acbb-9e0585424af2",
   "metadata": {},
   "source": [
    "### 19. Defining the RAG Prompt Template\n",
    "\n",
    "This cell constructs a `ChatPromptTemplate` that:\n",
    "\n",
    "- Sets the role of the assistant as a GDPR specialist.\n",
    "- Instructs it to use **only** the provided context.\n",
    "- Encourages citing articles and pages wherever possible.\n",
    "\n",
    "The template has two dynamic fields: `{context}` and `{question}`, which are filled in by the RAG chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "919b9e46-fbb4-4211-b8b1-87016aa8f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = ChatPromptTemplate.from_template(\n",
    "    textwrap.dedent(\n",
    "        \"\"\"\n",
    "        You are a GDPR assistant. Answer ONLY using the context below.\n",
    "        If the answer is not contained in the context, say you don't know\n",
    "        or that the regulation does not specify.\n",
    "\n",
    "        Always:\n",
    "        - Mention article and page if available.\n",
    "        - Quote short relevant passages with [page, article] tags.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec5f27-df9e-49c4-9102-caeb1aa8deca",
   "metadata": {},
   "source": [
    "### 20. Building the Baseline RAG Chain\n",
    "\n",
    "This cell composes the baseline RAG pipeline:\n",
    "\n",
    "1. Given a question, it retrieves relevant chunks and formats them as context.\n",
    "2. Fills the `rag_prompt` template.\n",
    "3. Sends the prompt to the chat model.\n",
    "\n",
    "The result is a grounded GDPR answer generated by the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2153c43-bfdd-41e3-a85a-3d6b372820cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(format_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    ")\n",
    "print(\"hello\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f6c0c0-426e-48e4-87cc-c5efe1f300a5",
   "metadata": {},
   "source": [
    "### 21. Disabling LangSmith / LangChain Tracing\n",
    "\n",
    "This cell explicitly disables all tracing-related environment variables:\n",
    "\n",
    "- Turns off LangChain and LangSmith tracing.\n",
    "- Ensures no external logging or monitoring endpoints are used.\n",
    "\n",
    "This makes the notebook self-contained and avoids sending trace data elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ce2c83-191d-4a84-8f01-8f32ec380254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ.pop(\"LANGSMITH_API_KEY\", None)\n",
    "os.environ.pop(\"LANGCHAIN_API_KEY\", None)\n",
    "\n",
    "import os\n",
    "\n",
    "# Hard-disable LangSmith / LangChain tracing in this notebook\n",
    "for var in [\n",
    "    \"LANGCHAIN_TRACING_V2\",\n",
    "    \"LANGCHAIN_TRACING\",\n",
    "    \"LANGCHAIN_ENDPOINT\",\n",
    "    \"LANGCHAIN_PROJECT\",\n",
    "    \"LANGSMITH_API_KEY\",\n",
    "    \"LANGCHAIN_API_KEY\",\n",
    "]:\n",
    "    os.environ.pop(var, None)\n",
    "\n",
    "print(\"Tracing disabled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80a862-2667-47a5-b804-7c1c41ce51e0",
   "metadata": {},
   "source": [
    "### 22. Testing the Baseline RAG Pipeline\n",
    "\n",
    "Here we run a simple test query:\n",
    "\n",
    "> *\"What are the lawful bases for processing personal data under GDPR?\"*\n",
    "\n",
    "The question is passed through `rag_chain`, and the model’s grounded answer is printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91d1b6a7-751a-4f8f-96fa-7360f7edbc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing baseline RAG...\n",
      "\n",
      "=== Baseline RAG Answer ===\n",
      "\n",
      "The lawful bases for processing personal data under GDPR include:\n",
      "\n",
      "1. **Union law or Member State law**: The processing must be laid down by Union law or Member State law to which the controller is subject [page 35, article unknown].\n",
      "\n",
      "2. **Public interest or official authority**: Processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller [page 35, article unknown; page 8, article unknown].\n",
      "\n",
      "3. **Legitimate interests**: Processing may be based on the legitimate interests pursued by the controller or by a third party, provided that these interests do not override the fundamental rights and freedoms of the data subject [page 41, article 6].\n",
      "\n",
      "4. **Consent**: Processing can also be based on the consent of the data subject, which can be withdrawn at any time [page 41, article 6].\n",
      "\n",
      "These bases ensure that the processing of personal data is lawful and fair.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_question = \"What are the lawful bases for processing personal data under GDPR?\"\n",
    "print(\"Testing baseline RAG...\")\n",
    "response = rag_chain.invoke(test_question)\n",
    "print(\"\\n=== Baseline RAG Answer ===\\n\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f1c03-b53f-4385-b027-154f870f4cdf",
   "metadata": {},
   "source": [
    "### 23. Section: Memory-Enhanced RAG\n",
    "\n",
    "This comment marks the start of the section where the basic RAG pipeline is extended with conversational memory to support multi-turn interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f2cf8e3-8bfa-449d-9985-8e1ad2c89f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Memory-Enhanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39d8f3-9859-4c04-a355-d3dbdbeea7b8",
   "metadata": {},
   "source": [
    "### 24. Building a Memory-Aware RAG Chain\n",
    "\n",
    "This cell:\n",
    "\n",
    "- Creates an in-memory dictionary `store` to hold chat histories keyed by `session_id`.\n",
    "- Defines `get_session_history` to fetch or create a `ChatMessageHistory`.\n",
    "- Builds `rag_chain_for_memory`, which accepts both a question and a conversation history and then runs the same retrieval + prompt + LLM pipeline.\n",
    "\n",
    "It sets the foundation for multi-turn conversations grounded in GDPR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50385c12-206a-49bb-aa73-df668644c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "store: Dict[str, ChatMessageHistory] = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# This chain expects {\"question\": \"...\", \"history\": [...]}\n",
    "rag_chain_for_memory = (\n",
    "    {\n",
    "        \"context\": RunnableLambda(lambda x: x[\"question\"]) | retriever | RunnableLambda(format_docs),\n",
    "        \"question\": RunnableLambda(lambda x: x[\"question\"]),\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe4986-68d0-43a6-b02d-8c9209256a53",
   "metadata": {},
   "source": [
    "### 25. Wrapping the Chain with Message History\n",
    "\n",
    "This cell wraps `rag_chain_for_memory` inside `RunnableWithMessageHistory`, so:\n",
    "\n",
    "- The agent automatically keeps track of past messages.\n",
    "- Future questions in the same session can reference previous context.\n",
    "\n",
    "The result is `conversational_rag`, a conversational RAG agent with memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f9af2a9-5a19-4aee-abc1-549046423365",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag = RunnableWithMessageHistory(\n",
    "    rag_chain_for_memory,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee0b67-2650-4b35-86b9-4acd7f7132cb",
   "metadata": {},
   "source": [
    "### 26. Helper Function for Memory-Based Chat\n",
    "\n",
    "This helper function provides a simple interface:\n",
    "\n",
    "- Takes a `question` and a `session_id`.\n",
    "- Invokes the `conversational_rag` chain with that session.\n",
    "- Returns only the generated answer text.\n",
    "\n",
    "It is used to demonstrate memory-aware conversations in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0deaa708-b27d-4a4e-8e33-b661c43ee0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_memory(question: str, session_id: str = \"demo-session\") -> str:\n",
    "    result = conversational_rag.invoke(\n",
    "        {\"question\": question},\n",
    "        config={\"configurable\": {\"session_id\": session_id}},\n",
    "    )\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcaa797-d8cf-42ad-8e10-22371bcb04fe",
   "metadata": {},
   "source": [
    "### 27. Demonstrating Memory-Enhanced RAG\n",
    "\n",
    "This cell runs a two-turn conversation:\n",
    "\n",
    "1. Asks about lawful bases for processing personal data.\n",
    "2. Follows up with a clarification question about consent.\n",
    "\n",
    "The agent uses the conversation history so the second answer can build on the first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b1ca3de-d3b8-47dd-9eda-cf96ce007358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Memory RAG Demo ===\n",
      "Q1: What are the lawful bases for processing personal data?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: AttributeError(\"'ChatMessageHistory' object has no attribute 'add_messages'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1: The lawful bases for processing personal data include:\n",
      "\n",
      "1. **Contractual necessity**: Processing is lawful where it is necessary in the context of a contract or the intention to enter into a contract [page 7, article unknown].\n",
      "\n",
      "2. **Legal obligation**: Processing carried out in accordance with a legal obligation to which the controller is subject or necessary for the performance of a task carried out in the public interest or in the exercise of official authority [page 7, article unknown].\n",
      "\n",
      "3. **Public interest**: Processing necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller [page 8, article unknown].\n",
      "\n",
      "4. **Legitimate interests**: The legitimate interests of a controller, provided that the interests or fundamental rights and freedoms of the data subject are not overriding [page 8, article unknown]. \n",
      "\n",
      "5. **Vital interests**: Processing based on the vital interest of another natural person, which should take place only where it cannot be manifestly based on another legal basis [page 8, article unknown]. \n",
      "\n",
      "These bases allow for lawful processing under various circumstances as specified in the regulation.\n",
      "\n",
      "Q2: Can you explain the one related to consent in simpler terms?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: AttributeError(\"'ChatMessageHistory' object has no attribute 'add_messages'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2: Consent under GDPR means that individuals must clearly agree to the processing of their personal data. This agreement can be given in various ways, such as through a written statement, ticking a box online, or other clear actions. However, simply being silent or having pre-ticked boxes does not count as consent. \n",
      "\n",
      "Consent must cover all purposes for which the data will be used, and if there are multiple purposes, consent must be obtained for each one. When asking for consent electronically, the request should be straightforward and not disrupt the service being provided. \n",
      "\n",
      "Additionally, individuals have the right to withdraw their consent at any time, and it should be just as easy to withdraw consent as it was to give it. Consent is not considered freely given if there is an imbalance of power between the individual and the organization asking for consent, such as when a public authority is involved [page 5, article unknown; page 36, article 7].\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Memory RAG Demo ===\")\n",
    "print(\"Q1:\", \"What are the lawful bases for processing personal data?\")\n",
    "print(\"A1:\", chat_with_memory(\"What are the lawful bases for processing personal data?\"))\n",
    "print(\"\\nQ2:\", \"Can you explain the one related to consent in simpler terms?\")\n",
    "print(\"A2:\", chat_with_memory(\"Can you explain the one related to consent in simpler terms?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696594c-8244-4d8c-93ac-69fd29829379",
   "metadata": {},
   "source": [
    "### 28. Section: Guardrails for Input and Output\n",
    "\n",
    "This comment marks the start of the section where simple guardrails are introduced to:\n",
    "\n",
    "- Filter unsafe or non-compliant user queries.\n",
    "- Post-process model outputs to detect possible hallucinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e870fd92-9c31-4bda-ac50-8b7febaed1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardrails: Input & Output Filters (Phase 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c5579-1115-44af-9d2b-7fd7fbf84f90",
   "metadata": {},
   "source": [
    "### 29. Input Safety Filter\n",
    "\n",
    "This function implements a basic input guard:\n",
    "\n",
    "- It scans the question for suspicious patterns that suggest attempts to bypass GDPR.\n",
    "- If any pattern is found, it raises an error instead of answering.\n",
    "- Otherwise, it returns the original question.\n",
    "\n",
    "This is a minimal example of adding compliance guardrails on user input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c8fd6d2-7ec0-4586-8c2e-a4c7930cfaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_safety_filter(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Very simple adversarial filter.\n",
    "    You can extend this with more NLP-based detectors.\n",
    "    \"\"\"\n",
    "    lower_q = question.lower()\n",
    "    blocked_patterns = [\n",
    "        \"bypass gdpr\",\n",
    "        \"evade gdpr\",\n",
    "        \"ignore gdpr\",\n",
    "        \"trick the regulator\",\n",
    "        \"fake consent\",\n",
    "    ]\n",
    "    if any(p in lower_q for p in blocked_patterns):\n",
    "        raise ValueError(\n",
    "            \"Your query appears to ask for non-compliant or unethical behavior. \"\n",
    "            \"I cannot help with that.\"\n",
    "        )\n",
    "    return question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80eaeed-e4ed-452b-8624-871201c38e4d",
   "metadata": {},
   "source": [
    "### 30. Output Hallucination Guard\n",
    "\n",
    "This guard checks the final answer:\n",
    "\n",
    "- If the answer does not mention “GDPR” or “Article”, it may not be sufficiently grounded in the regulation.\n",
    "- In that case, it adds a warning message before returning the answer.\n",
    "\n",
    "This is a lightweight way to flag potentially ungrounded responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16cdd80c-ecc6-4f4b-b121-35857dda843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hallucination_guard(answer: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple output guard:\n",
    "    - Enforce that answer mentions at least 'GDPR' or 'Article'\n",
    "    - If not, warn user.\n",
    "    \"\"\"\n",
    "    if (\"article\" not in answer.lower()) and (\"gdpr\" not in answer.lower()):\n",
    "        return (\n",
    "            \"Warning: The model's answer may be insufficiently grounded in GDPR text.\\n\\n\"\n",
    "            + answer\n",
    "        )\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a34a0a-ae5f-41d2-8c95-33f4c8c2c2ee",
   "metadata": {},
   "source": [
    "### 31. Combining Guardrails with the RAG Chain\n",
    "\n",
    "This cell:\n",
    "\n",
    "1. Wraps the baseline `rag_chain` with:\n",
    "   - `input_safety_filter` before the model call.\n",
    "   - `hallucination_guard` after the model call.\n",
    "2. Demonstrates:\n",
    "   - A blocked unsafe query.\n",
    "   - A normal GDPR query that passes and gets answered.\n",
    "\n",
    "The result is a safer RAG pipeline for GDPR-related questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "985e718a-49e1-4f31-afb6-d11bb3f9f5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Guardrails Demo ===\n",
      "Bad query: How can I bypass GDPR to process user data without them knowing?\n",
      "Blocked bad query: Your query appears to ask for non-compliant or unethical behavior. I cannot help with that.\n",
      "\n",
      "Good query: Explain when consent is required under GDPR.\n",
      "Answer: The regulation specifies that consent is required when processing is based on the data subject's consent. The controller must be able to demonstrate that the data subject has consented to the processing of their personal data [page 5, article unknown]. Additionally, consent must be given in a manner that is clearly distinguishable from other matters, intelligible, and easily accessible, using clear and plain language [page 36, article unknown]. \n",
      "\n",
      "Consent should cover all processing activities for the same purpose or purposes, and if there are multiple purposes, consent must be given for all of them [page 5, article unknown].\n"
     ]
    }
   ],
   "source": [
    "safe_rag_chain = (\n",
    "    RunnableLambda(lambda q: input_safety_filter(q))\n",
    "    | rag_chain\n",
    "    | RunnableLambda(lambda msg: hallucination_guard(msg.content))\n",
    ")\n",
    "\n",
    "print(\"\\n=== Guardrails Demo ===\")\n",
    "try:\n",
    "    bad_q = \"How can I bypass GDPR to process user data without them knowing?\"\n",
    "    print(\"Bad query:\", bad_q)\n",
    "    print(\"Answer:\", safe_rag_chain.invoke(bad_q))\n",
    "except Exception as e:\n",
    "    print(\"Blocked bad query:\", e)\n",
    "\n",
    "good_q = \"Explain when consent is required under GDPR.\"\n",
    "print(\"\\nGood query:\", good_q)\n",
    "print(\"Answer:\", safe_rag_chain.invoke(good_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1a23b-7017-4a28-9d30-6bf3ead4f6f0",
   "metadata": {},
   "source": [
    "### 32. Section: Agentic RAG with Tools\n",
    "\n",
    "This comment introduces the section where the system is extended with simple “tools” that the agent can use, such as retrieval and summarization utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ca5b099-88f4-4b90-880f-087d5b08b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic RAG with Simple Tools (Phase 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124574ae-f3d4-4189-879b-ef47bfb0b619",
   "metadata": {},
   "source": [
    "### 33. Retrieval and Citation Tools\n",
    "\n",
    "This cell defines two utility “tools”:\n",
    "\n",
    "- `retrieve_tool`: fetches the top-k most relevant chunks for a given query.\n",
    "- `citation_check_tool`: performs a basic check to see whether the final answer appears to reference pages/articles from the retrieved documents.\n",
    "\n",
    "These tools can be used by a more agent-like pipeline to reason about context and citations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ab35711-d52f-4dad-a261-dc184847c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tool(query: str, k: int = 5):\n",
    "    \"\"\"Tool: retrieve top-k relevant GDPR chunks.\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return docs[:k]\n",
    "\n",
    "def citation_check_tool(answer: str, docs: List[Any]) -> bool:\n",
    "    \"\"\"\n",
    "    Very naive citation check:\n",
    "    - Just check if any page/article markers used in format_docs appear in answer.\n",
    "    \"\"\"\n",
    "    markers = []\n",
    "    for d in docs:\n",
    "        page = d.metadata.get(\"page\", \"?\")\n",
    "        article = d.metadata.get(\"article\", \"unknown\")\n",
    "        markers.append(f\"page {page}\")\n",
    "        markers.append(f\"article {article}\")\n",
    "    return any(m.lower() in answer.lower() for m in markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e075ba-1018-4133-b250-4b61a34ebe04",
   "metadata": {},
   "source": [
    "### 34. Summarization Tool\n",
    "\n",
    "This tool takes retrieved documents and a question, and uses the LLM to generate a focused summary or answer.  \n",
    "It demonstrates how the RAG system can expose more specialized helper functions beyond basic retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ee5532b-2987-4468-9c86-4739a519e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer_tool(docs: List[Any], question: str) -> str:\n",
    "    \"\"\"Summarizer tool uses LLM to compress docs into a focused answer.\"\"\"\n",
    "    context = format_docs(docs)\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        textwrap.dedent(\n",
    "            \"\"\"\n",
    "            You are a GDPR summarizer.\n",
    "            Use ONLY the context below to answer the question.\n",
    "            Provide a concise, well-structured explanation with citations.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            {question}\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"context\": context, \"question\": question})\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0555d-29e6-4409-a02e-b71bba15d351",
   "metadata": {},
   "source": [
    "### 35. Agentic RAG Orchestration\n",
    "\n",
    "This function coordinates the use of tools (retrieval, summarization, citation checking) to answer a question in a slightly more “agentic” manner, rather than a single-pass RAG call.  \n",
    "It showcases how higher-level logic can be layered on top of the basic RAG building blocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d018860-be35-4f51-8a93-cb353111f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agentic RAG Demo ===\n",
      "Question: What are data subject rights under GDPR?\n",
      "Answer: Under the General Data Protection Regulation (GDPR), data subjects have several key rights designed to protect their personal data and ensure transparency in its processing. These rights include:\n",
      "\n",
      "1. **Right of Access**: Data subjects have the right to obtain confirmation from the data controller regarding whether their personal data is being processed. If so, they can access their personal data and receive information about the purposes of processing, categories of data, recipients of the data, storage duration, and their rights to rectification or erasure (Article 15) (page 42).\n",
      "\n",
      "2. **Right to Object**: Data subjects can object to the processing of their personal data, particularly when it is processed for scientific, historical, or statistical purposes, unless the processing is necessary for a task carried out in the public interest (Article 89) (page 45).\n",
      "\n",
      "3. **Right to Transparent Information**: Controllers must provide information regarding data processing in a concise, transparent, intelligible, and easily accessible form. This includes clear communication about the rights of data subjects (Article 12) (page 38).\n",
      "\n",
      "4. **Right to Rectification and Erasure**: Data subjects have the right to request the rectification of inaccurate personal data and the erasure of their personal data under certain conditions (Article 15) (page 42).\n",
      "\n",
      "5. **Right to Access Health Data**: Specifically, data subjects have the right to access personal data related to their health, such as medical records, which includes diagnoses and treatment information (page 11).\n",
      "\n",
      "These rights empower individuals to have control over their personal data and ensure that they are informed about how their data is being used.\n"
     ]
    }
   ],
   "source": [
    "def agentic_rag(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple agent:\n",
    "    1. Apply input guardrails\n",
    "    2. Use retrieve_tool\n",
    "    3. Use summarizer_tool\n",
    "    4. Run citation_check_tool; if fails, warn user\n",
    "    \"\"\"\n",
    "    q = input_safety_filter(question)\n",
    "    docs = retrieve_tool(q, k=5)\n",
    "    if not docs:\n",
    "        return \"I couldn't find any relevant GDPR content to answer this question.\"\n",
    "\n",
    "    answer = summarizer_tool(docs, q)\n",
    "    has_citations = citation_check_tool(answer, docs)\n",
    "    if not has_citations:\n",
    "        answer = (\n",
    "            \"Note: The generated answer may be missing explicit citations; \"\n",
    "            \"please verify against GDPR text.\\n\\n\"\n",
    "            + answer\n",
    "        )\n",
    "    return answer\n",
    "\n",
    "print(\"\\n=== Agentic RAG Demo ===\")\n",
    "print(\"Question:\", \"What are data subject rights under GDPR?\")\n",
    "print(\"Answer:\", agentic_rag(\"What are data subject rights under GDPR?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d06b54-6990-490e-9009-817df87a488a",
   "metadata": {},
   "source": [
    "### 36. Section: Graph-RAG Style Retrieval\n",
    "\n",
    "This comment introduces an experimental “Graph-RAG” approach, where the system can reason about related sections or neighbors in the text, instead of treating chunks as independent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0de6c87d-8fd2-425e-99f1-cf11950082c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph-RAG Style Retrieval (Phase 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f89771-cb4e-4409-acfc-13543d1929f8",
   "metadata": {},
   "source": [
    "### 37. Regulatory Rephrasing Helper\n",
    "\n",
    "This helper function rewrites user questions into a more formal or regulation-oriented phrasing.  \n",
    "The goal is to make queries align better with how GDPR is written, potentially improving retrieval quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "991446d2-7148-41d7-af07-790b1dd8dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regulatory_rephrase(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Use the LLM to rephrase a natural question into more 'regulation-like' language.\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        textwrap.dedent(\n",
    "            \"\"\"\n",
    "            Rephrase the user question into a GDPR-regulation-style query,\n",
    "            referencing articles or sections if appropriate.\n",
    "            Do NOT answer the question, only rephrase it.\n",
    "\n",
    "            User question: {question}\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    return result.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65d164-9568-4caf-b2cb-243efb943b61",
   "metadata": {},
   "source": [
    "### 38. Retrieving Anchor and Neighbor Chunks\n",
    "\n",
    "This function performs a retrieval step that not only finds the most relevant “anchor” chunks but also includes neighboring chunks.  \n",
    "This can approximate a graph-style neighborhood around relevant GDPR passages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9467233a-0554-4720-a4dd-f64160889c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor_and_neighbors(question: str):\n",
    "    \"\"\"\n",
    "    1. Rephrase to regulatory language\n",
    "    2. Get anchor doc\n",
    "    3. Get neighbors: same page +/- 1, or same article if available\n",
    "    \"\"\"\n",
    "    ref_q = regulatory_rephrase(question)\n",
    "    # NEW: use retriever.invoke instead of get_relevant_documents\n",
    "    anchor_docs = retriever.invoke(ref_q)\n",
    "    if not anchor_docs:\n",
    "        return None, []\n",
    "\n",
    "    anchor = anchor_docs[0]\n",
    "    anchor_page = anchor.metadata.get(\"page\", None)\n",
    "    anchor_article = anchor.metadata.get(\"article\", None)\n",
    "\n",
    "    neighbors = []\n",
    "    for d in chunks:\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        article = d.metadata.get(\"article\", None)\n",
    "\n",
    "        # Same article OR neighboring pages\n",
    "        if anchor_article != \"unknown\" and article == anchor_article:\n",
    "            neighbors.append(d)\n",
    "        elif anchor_page is not None and page in {anchor_page - 1, anchor_page, anchor_page + 1}:\n",
    "            neighbors.append(d)\n",
    "\n",
    "    # Deduplicate neighbors\n",
    "    seen_ids = set()\n",
    "    unique_neighbors = []\n",
    "    for d in neighbors:\n",
    "        key = (d.metadata.get(\"page\"), d.metadata.get(\"article\"), d.page_content[:50])\n",
    "        if key not in seen_ids:\n",
    "            seen_ids.add(key)\n",
    "            unique_neighbors.append(d)\n",
    "\n",
    "    return anchor, unique_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad7b08-0333-471d-8ef6-72c759de4f37",
   "metadata": {},
   "source": [
    "### 39. Graph-RAG Style Answering\n",
    "\n",
    "This function uses the anchor-and-neighbor context to generate an answer that accounts for related GDPR passages.  \n",
    "It illustrates how retrieval strategies beyond simple top-k search can be integrated into RAG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a63d4403-fe75-45a2-928f-4c15a1b50c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Graph-RAG Demo ===\n",
      "Question: When is a Data Protection Impact Assessment (DPIA) required under GDPR?\n",
      "Answer: A Data Protection Impact Assessment (DPIA) is required under the General Data Protection Regulation (GDPR) when processing operations are likely to result in a high risk to the rights and freedoms of natural persons. Specifically, this requirement is outlined in the context of Article 35 of the GDPR, which mandates that the controller must carry out a DPIA to evaluate the origin, nature, particularity, and severity of the risk involved in the processing.\n",
      "\n",
      "According to the context provided, if the DPIA indicates that the processing operations involve a high risk that cannot be mitigated by appropriate measures (considering available technology and costs of implementation), the controller must consult the supervisory authority prior to the processing (see page 15).\n",
      "\n",
      "Additionally, the likelihood and severity of the risk should be assessed based on the nature, scope, context, and purposes of the processing (see page 14, Article 76). This assessment should be objective and determine whether the processing operations involve a risk or a high risk (see page 14, Article 76).\n",
      "\n",
      "In summary, a DPIA is required when:\n",
      "1. The processing is likely to result in a high risk to the rights and freedoms of natural persons.\n",
      "2. The DPIA indicates that the risks cannot be mitigated, necessitating consultation with the supervisory authority.\n",
      "\n",
      "---\n",
      "Traceability Note:\n",
      "- Anchor page: 15\n",
      "- Anchor article: unknown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def graph_rag_answer(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Graph-like RAG:\n",
    "    - Rephrase\n",
    "    - Anchor retrieval + neighbors\n",
    "    - Summarize\n",
    "    - Add page/article citations and optional full-page snippet\n",
    "    \"\"\"\n",
    "    try:\n",
    "        q = input_safety_filter(question)\n",
    "    except ValueError as e:\n",
    "        return str(e)\n",
    "\n",
    "    anchor, neighbors = get_anchor_and_neighbors(q)\n",
    "    if anchor is None:\n",
    "        return \"I couldn't locate relevant GDPR sections for this question.\"\n",
    "\n",
    "    # Use anchor + top neighbors as context\n",
    "    context_docs = [anchor] + neighbors[:8]\n",
    "    context = format_docs(context_docs)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        textwrap.dedent(\n",
    "            \"\"\"\n",
    "            You are a GDPR legal assistant using graph-enhanced retrieval.\n",
    "            Answer based ONLY on the context below.\n",
    "            Make sure to:\n",
    "            - Mention relevant Articles explicitly.\n",
    "            - Describe any conditions or exceptions.\n",
    "            - Provide page and article references.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            {question}\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    answer = chain.invoke({\"context\": context, \"question\": q}).content\n",
    "\n",
    "    # Attach an optional snippet of the anchor page for traceability\n",
    "    anchor_page = anchor.metadata.get(\"page\", \"?\")\n",
    "    trailer = textwrap.dedent(\n",
    "        f\"\"\"\n",
    "        ---\n",
    "        Traceability Note:\n",
    "        - Anchor page: {anchor_page}\n",
    "        - Anchor article: {anchor.metadata.get(\"article\", \"unknown\")}\n",
    "        \"\"\"\n",
    "    )\n",
    "    return answer + \"\\n\" + trailer\n",
    "\n",
    "print(\"\\n=== Graph-RAG Demo ===\")\n",
    "print(\"Question:\", \"When is a Data Protection Impact Assessment (DPIA) required under GDPR?\")\n",
    "print(\"Answer:\", graph_rag_answer(\"When is a Data Protection Impact Assessment (DPIA) required under GDPR?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b731581-c901-4f46-9bf1-14225003e8e4",
   "metadata": {},
   "source": [
    "### 40. Section: LangGraph Agent with Memory\n",
    "\n",
    "This comment introduces a minimal LangGraph-based agent that combines:\n",
    "\n",
    "- RAG retrieval,\n",
    "- conversational memory,\n",
    "- and stateful graph execution.\n",
    "\n",
    "It serves as a higher-level “shell” around the existing components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e18c81d-6ebe-444b-935c-5b6e7b3ad972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph + Memory (Agent Shell) (Phase 5 + 3, minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f55312b9-ade0-4e19-820e-642ea26b8c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LangGraph Conversation Demo ===\n",
      "HumanMessage : Summarize the principles of data processing under GDPR.\n",
      "AIMessage : The principles of data processing under GDPR are outlined in Article 5. They include:\n",
      "\n",
      "1. **Lawfulness, Fairness, and Transparency**: Personal data must be processed lawfully, fairly, and in a transparent manner in relation to the data subject [page 34, article 5].\n",
      "\n",
      "2. **Purpose Limitation**: Data should be collected for specified, explicit, and legitimate purposes and not further processed in a manner incompatible with those purposes. However, further processing for archiving in the public interest, scientific or historical research, or statistical purposes is permitted under certain conditions [page 34, article 5].\n",
      "\n",
      "3. **Data Minimization**: Although not explicitly mentioned in the provided context, this principle generally requires that personal data collected should be adequate, relevant, and limited to what is necessary for the purposes for which they are processed.\n",
      "\n",
      "4. **Accuracy**: Personal data should be accurate and kept up to date. Every reasonable step must be taken to ensure that inaccurate data is rectified or deleted [page 6, article unknown].\n",
      "\n",
      "5. **Storage Limitation**: Personal data should not be kept longer than necessary for the purposes for which it is processed. Time limits for erasure or periodic review should be established [page 6, article unknown].\n",
      "\n",
      "6. **Integrity and Confidentiality**: Personal data must be processed in a manner that ensures appropriate security and confidentiality, including protection against unauthorized access [page 6, article unknown].\n",
      "\n",
      "7. **Accountability**: While not explicitly stated in the provided context, this principle generally requires that the data controller is responsible for and must be able to demonstrate compliance with the other principles.\n",
      "\n",
      "These principles ensure that personal data is handled responsibly and with respect for the rights of individuals.\n"
     ]
    }
   ],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "def rag_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node that uses the safe_rag_chain as backend.\n",
    "    We read the latest human message and return an AI message.\n",
    "    \"\"\"\n",
    "    # Last human message\n",
    "    last_human = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            last_human = m\n",
    "            break\n",
    "\n",
    "    if last_human is None:\n",
    "        return {\"messages\": [AIMessage(content=\"No user question found.\")]}\n",
    "\n",
    "    question = last_human.content\n",
    "    try:\n",
    "        answer = safe_rag_chain.invoke(question)\n",
    "        if hasattr(answer, \"content\"):\n",
    "            text = answer.content\n",
    "        else:\n",
    "            text = str(answer)\n",
    "    except Exception as e:\n",
    "        text = f\"Error while answering question: {e}\"\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=text)]}\n",
    "\n",
    "# Build graph\n",
    "graph_builder = StateGraph(GraphState)\n",
    "graph_builder.add_node(\"rag_node\", rag_node)\n",
    "graph_builder.set_entry_point(\"rag_node\")\n",
    "graph_builder.add_edge(\"rag_node\", END)\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph_app = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"\\n=== LangGraph Conversation Demo ===\")\n",
    "initial_state: GraphState = {\n",
    "    \"messages\": [HumanMessage(content=\"Summarize the principles of data processing under GDPR.\")]\n",
    "}\n",
    "result_state = graph_app.invoke(\n",
    "    initial_state,\n",
    "    config={\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    ")\n",
    "for msg in result_state[\"messages\"]:\n",
    "    print(type(msg).__name__, \":\", msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62712ca1-9ee7-4550-89f7-478905a9fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Simple Robustness & Hallucination Test (Phase 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a73895f0-6812-4d37-995a-887af5350d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Robustness / Hallucination Demo ===\n",
      "Real question: What is Article 6 about?\n",
      "Answer: Note: The generated answer may be missing explicit citations; please verify against GDPR text.\n",
      "\n",
      "The provided context does not include specific information about Article 6 of the GDPR. Therefore, I cannot summarize or explain its content based on the given text. If you have access to the text of Article 6 or any additional context, please provide it for a more accurate response.\n",
      "\n",
      "Fake question: What does non-existent Article 999 say?\n",
      "Answer: The context provided does not contain any information regarding a non-existent Article 999. Therefore, I cannot provide a summary or explanation about it. The articles referenced include Article 52, which discusses the independence of supervisory authorities, Article 49, which outlines conditions for transferring personal data to third countries, and Article 94, which addresses the repeal of Directive 95/46/EC. If you have questions about these specific articles or any other related topics, feel free to ask!\n",
      "\n",
      "All phases executed. Your GDPR RAG system is up and running.\n"
     ]
    }
   ],
   "source": [
    "def robust_ask(question: str) -> str:\n",
    "    \"\"\"\n",
    "    - Uses retriever directly\n",
    "    - If no docs, refuses to answer\n",
    "    - Otherwise uses agentic_rag for grounded answer\n",
    "    \"\"\"\n",
    "    # In the new API, retriever is a Runnable, so we use .invoke(...)\n",
    "    docs = retriever.invoke(question)\n",
    "    if not docs:\n",
    "        return \"I could not find sufficiently relevant GDPR text. I prefer not to answer rather than hallucinate.\"\n",
    "\n",
    "    return agentic_rag(question)\n",
    "\n",
    "print(\"\\n=== Robustness / Hallucination Demo ===\")\n",
    "print(\"Real question:\", \"What is Article 6 about?\")\n",
    "print(\"Answer:\", robust_ask(\"What is Article 6 about?\"))\n",
    "\n",
    "print(\"\\nFake question:\", \"What does non-existent Article 999 say?\")\n",
    "print(\"Answer:\", robust_ask(\"What does non-existent Article 999 say?\"))\n",
    "\n",
    "print(\"\\nAll phases executed. Your GDPR RAG system is up and running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578fcadd-667e-4cac-bd69-14a39829be60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
